{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e3db3e",
   "metadata": {},
   "source": [
    "Step 1: Ingestion and Clause identification.\n",
    "\n",
    "    User uploads TA. Function splits user uploaded TA into meangingful clauses  \n",
    "\n",
    "Step 2: Clause Comparison. RAG 1 for Tenancy Agreement\n",
    "\n",
    "    Vector store: RAG 1 - Ideal Clauses from reference TAs\n",
    "    Compare and retrieve: Retrieve relevant RAG clauses based on similarity to clauses in user uploaded TA\n",
    "    LLM evaluation: Use LLM to compare user clause and ideal clauses. Provide feedback on TA through a report\n",
    "\n",
    "Step 3: Post-Report Q and A from User. RAG 2 for Q and A\n",
    "\n",
    "    Vector store: RAG 2 - Q and A from Database Requirements.xlsx\n",
    "    Compare and retrieve: Retrieve relevant RAG Q and A clauses based on similarity to user's question\n",
    "    LLM evaluation: Use LLM to take in additional context from RAG to improve answer.\n",
    "\n",
    "Next Step: Template recomendation? Integrating law into RAG? \n",
    "\n",
    "    Currently we only compare clauses of our RAG database with uploaded user TA. No way to compare and say what clauses must be in the TA. Maybe we can include that in the prompt, instead of using RAG for this part? Like \"Tenancy agreement should have a, b, c, d clauses at minimum and most will also have e, f clauses\" Also need to figure out how to integrate legal documents into RAG 1 to help explain legality of certain clauses. Right now it just compares clauses in user TA to clauses in RAG database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427d0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import re\n",
    "# Core LangChain/HuggingFace RAG Imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# SentenceTransformer is replaced by HuggingFaceEmbeddings(model_name=...)\n",
    "# faiss is replaced by FAISS from langchain_community\n",
    "# We will still need numpy for the internal dataframe processing\n",
    "# We will use the already configured SentenceTransformer model name\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "K = 3 # Number of top results to retrieve\n",
    "\n",
    "# Initialize the shared embedding model once\n",
    "embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ee2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG 1: Ideal Clauses (The 'Gold Standard' for Comparison) ---\n",
    "def build_ideal_clauses_retriever(data_directory=\"./TA_template\"):\n",
    "    \"\"\"\n",
    "    Loads, chunks, and indexes the ideal tenancy agreement PDFs (RAG 1 source).\n",
    "    Returns a LangChain FAISS Retriever.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- BUILDING RAG 1: IDEAL CLAUSES RETRIEVER ---\")\n",
    "    \n",
    "    # 1. Load Documents\n",
    "    loader = DirectoryLoader(\n",
    "        path=data_directory,\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "        show_progress=True\n",
    "    )\n",
    "    all_documents = loader.load()\n",
    "    print(f\"Loaded {len(all_documents)} document pages.\")\n",
    "\n",
    "    # 2. Chunk Documents (using the custom, structure-aware splitter)\n",
    "    custom_separators = [\n",
    "        \"\\n\\n\",\n",
    "        r\"\\n\\s*[A-Z]+\\s+\\d*\\s*\\.\",\n",
    "        r\"\\n\\s*\\d+\\.\\d*\\s*\",\n",
    "        r\"\\n\\s*\\([a-zA-Z0-9]+\\)\\s*\",\n",
    "        \"\\n\", \" \", \"\"\n",
    "    ]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200,\n",
    "        separators=custom_separators,\n",
    "        is_separator_regex=True\n",
    "    )\n",
    "    all_chunks = text_splitter.split_documents(all_documents)\n",
    "    print(f\"Split into {len(all_chunks)} chunks.\")\n",
    "\n",
    "    print(\"\\n--- IDEAL CLAUSES CHUNK PREVIEW (First 3) ---\")\n",
    "    for i, chunk in enumerate(all_chunks[:3]):\n",
    "        print(f\"Chunk {i+1} (Length: {len(chunk.page_content)}):\")\n",
    "        # Print the first 200 characters to keep the output manageable\n",
    "        print(f\"  {chunk.page_content[:200].replace('\\n', ' ')}...\") \n",
    "        print(f\"  Metadata: {chunk.metadata}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "\n",
    "    # 3. Create Vector Store and Retriever\n",
    "    vectorstore = FAISS.from_documents(all_chunks, embeddings)\n",
    "    print(\"FAISS index for Ideal Clauses created successfully.\")\n",
    "    \n",
    "    # Return the retriever instance\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a1251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document # Import required for conversion\n",
    "\n",
    "# --- RAG 2: General Q&A (Excel Source) ---\n",
    "def build_general_qa_retriever(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from the Excel file, converts it to Documents, and creates a FAISS retriever.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- BUILDING RAG 2: GENERAL Q&A RETRIEVER ---\")\n",
    "    \n",
    "    # 1. Load and process data (using the existing logic)\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, header=1)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found. Using dummy data.\")\n",
    "        df = pd.DataFrame({\n",
    "            'Question': [\"How do I know if my tenancy agreement is valid?\"],\n",
    "            'Answer / Explanation': [\"Must be in writing, signed by both parties, and include essential terms.\"],\n",
    "            'Legal Commentary': [\"Only agreements containing essential terms are enforceable.\"],\n",
    "            'Government Regulation / Explanation': [\"N/A\"]\n",
    "        })\n",
    "    \n",
    "    # 2. Convert Data Rows into LangChain Documents\n",
    "    documents = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = textwrap.dedent(f\"\"\"\n",
    "            Question: {row.get('Question', 'N/A')}\n",
    "            Answer/Explanation: {row.get('Answer / Explanation', 'N/A')}\n",
    "            Legal Context: {row.get('Legal Commentary', 'N/A')}\n",
    "            Regulation/Source: {row.get('Government Regulation / Explanation', 'N/A')}\n",
    "        \"\"\").strip()\n",
    "        \n",
    "        # Create a LangChain Document\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\"source\": file_path, \"row_index\": index}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "        \n",
    "    print(f\"Created {len(documents)} General Q&A Documents.\")\n",
    "\n",
    "    print(\"\\n--- GENERAL Q&A CHUNK PREVIEW (First 3) ---\")\n",
    "    for i, doc in enumerate(documents[:3]):\n",
    "        print(f\"Chunk {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "        print(f\"  Metadata: {doc.metadata}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    # 3. Create Vector Store and Retriever\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    print(\"FAISS index for General Q&A created successfully.\")\n",
    "    \n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BUILDING RAG 1: IDEAL CLAUSES RETRIEVER ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 17.81it/s]Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  5.63it/s]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      " 71%|███████▏  | 5/7 [00:00<00:00,  5.71it/s]Ignoring wrong pointing object 5 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 document pages.\n",
      "Split into 108 chunks.\n",
      "\n",
      "--- IDEAL CLAUSES CHUNK PREVIEW (First 3) ---\n",
      "Chunk 1 (Length: 903):\n",
      "  RENTAL AGREEMENT PROBLEMATIC RENTAL TERMS LANDLORD: ABC Property Company TENANT: John Doe RENTAL AMOUNT: S$3,500 per month SECURITY DEPOSIT: S$17,500 (5 months rent) - EXCESSIVE! LEASE PERIOD: 12 mont...\n",
      "  Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-08-31T22:29:15+08:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-08-31T22:29:15+08:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'TA_data\\\\TA1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "--------------------\n",
      "Chunk 2 (Length: 879):\n",
      "  RESIDENTIAL TENANCY AGREEMENT (Singapore) 1. PARTIES TO THE AGREEMENT LANDLORD: Mr. Tan Ah Beng NRIC: S1234567A Address: 123 Orchard Road, #15-01, Singapore 238123 Contact: +65 9123 4567 TENANT: Ms. S...\n",
      "  Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-08-31T22:29:15+08:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-08-31T22:29:15+08:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'TA_data\\\\TA2.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "--------------------\n",
      "Chunk 3 (Length: 665):\n",
      "  4. TERMS AND CONDITIONS 4.1 The Tenant shall pay the monthly rent punctually without any deduction or set-off. 4.2 The security deposit shall be refunded within 14 days after the expiry of this agreem...\n",
      "  Metadata: {'producer': 'ReportLab PDF Library - www.reportlab.com', 'creator': '(unspecified)', 'creationdate': '2025-08-31T22:29:15+08:00', 'author': '(anonymous)', 'keywords': '', 'moddate': '2025-08-31T22:29:15+08:00', 'subject': '(unspecified)', 'title': '(anonymous)', 'trapped': '/False', 'source': 'TA_data\\\\TA2.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "--------------------\n",
      "FAISS index for Ideal Clauses created successfully.\n",
      "\n",
      "--- BUILDING RAG 2: GENERAL Q&A RETRIEVER ---\n",
      "Created 53 General Q&A Documents.\n",
      "\n",
      "--- GENERAL Q&A CHUNK PREVIEW (First 3) ---\n",
      "Chunk 1:\n",
      "Question: How do I know if my tenancy agreement is valid?\n",
      "Answer/Explanation: Must be in writing, signed by both parties, and include essential terms (rent, duration, responsibilities).\n",
      "Legal Context: Only agreements containing essential terms are enforceable.\n",
      "Regulation/Source: nan\n",
      "  Metadata: {'source': 'Database Requirements.xlsx', 'row_index': 0}\n",
      "--------------------\n",
      "Chunk 2:\n",
      "Question: What should I do before signing a tenancy agreement?\n",
      "Answer/Explanation: Review all terms carefully; ensure clarity; consider legal advice. If there is an inventory list, thoroughly check the condition of the items and retain photo or video evidence.\n",
      "Legal Context: Legal review reduces risk of unenforceable clauses.\n",
      "Regulation/Source: nan\n",
      "  Metadata: {'source': 'Database Requirements.xlsx', 'row_index': 1}\n",
      "--------------------\n",
      "Chunk 3:\n",
      "Question: Can my landlord enter my property without notice?\n",
      "Answer/Explanation: Landlord must give reasonable notice (usually 24h), except emergencies. It is recommended to document the notice period in the agreement.\n",
      "Legal Context: Court upheld tenant’s right to quiet enjoyment.\n",
      "Regulation/Source: HDB/URA – Landlord must respect tenant’s quiet enjoyment; entry should be scheduled and reasonable\n",
      "  Metadata: {'source': 'Database Requirements.xlsx', 'row_index': 2}\n",
      "--------------------\n",
      "FAISS index for General Q&A created successfully.\n",
      "\n",
      "✅ BOTH RAG SYSTEMS ARE READY.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- PHASE 1: COMPARING USER AGREEMENT CLAUSES ---\n",
      "\n",
      "User Clause: (b) SECURITY DEPOSIT: The Tenant shall pay the Landlord a security deposit equal to $3,000. This deposit will not accrue interest.\n",
      "\n",
      "[SIMULATED LLM COMPARISON & FEEDBACK GENERATION]\n",
      "Retrieved Ideal Context for LLM:\n",
      "  - Length: 982. Source: TA_data\\TA7.pdf\n",
      "  - Length: 894. Source: TA_data\\TA6.pdf\n",
      "  - Length: 811. Source: TA_data\\TA3.pdf\n",
      "\n",
      "\n",
      "--- PHASE 2: GENERAL Q&A ---\n",
      "\n",
      "User Q&A Query: What rules apply to my landlord entering my rental?\n",
      "\n",
      "[SIMULATED LLM ANSWER GENERATION]\n",
      "Retrieved General Q&A Context for LLM:\n",
      "  - Length: 506. Source: Database Requirements.xlsx\n",
      "  - Length: 398. Source: Database Requirements.xlsx\n",
      "  - Length: 411. Source: Database Requirements.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Testing RAG 1 and 2\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_NAME = 'Database Requirements.xlsx'\n",
    "DATA_DIRECTORY = \"./TA_template\" \n",
    "\n",
    "# Initialize shared embedding model once\n",
    "embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. BUILD THE TWO RAG SYSTEMS\n",
    "    ideal_clauses_retriever = build_ideal_clauses_retriever(DATA_DIRECTORY)\n",
    "    general_qa_retriever = build_general_qa_retriever(FILE_NAME)\n",
    "\n",
    "    print(\"\\n✅ BOTH RAG SYSTEMS ARE READY.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    # --- SIMULATE THE PIPELINE EXECUTION ---\n",
    "    \n",
    "    # --- PHASE 1: CLAUSE IDENTIFICATION & COMPARISON (RAG 1) ---\n",
    "    print(\"\\n--- PHASE 1: COMPARING USER AGREEMENT CLAUSES ---\")\n",
    "    \n",
    "    # 1.1 Simulate a single clause from the user's uploaded document\n",
    "    # In the full app, you would run the text_splitter on the user upload here\n",
    "    user_clause_to_check = \"(b) SECURITY DEPOSIT: The Tenant shall pay the Landlord a security deposit equal to $3,000. This deposit will not accrue interest.\"\n",
    "    \n",
    "    # 1.2 Use RAG 1 to retrieve the Ideal Clause context\n",
    "    comparison_context = ideal_clauses_retriever.invoke(user_clause_to_check)\n",
    "    \n",
    "    # 1.3 LLM Call for Feedback (Simulated)\n",
    "    print(f\"\\nUser Clause: {user_clause_to_check}\")\n",
    "    print(\"\\n[SIMULATED LLM COMPARISON & FEEDBACK GENERATION]\")\n",
    "    print(f\"Retrieved Ideal Context for LLM:\")\n",
    "    for doc in comparison_context:\n",
    "        print(f\"  - Length: {len(doc.page_content)}. Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "    # *A real LLM would now compare the user clause to this context and generate a report.*\n",
    "\n",
    "    # --- PHASE 2: POST-FEEDBACK Q&A (RAG 2) ---\n",
    "    print(\"\\n\\n--- PHASE 2: GENERAL Q&A ---\")\n",
    "    \n",
    "    # 2.1 User enters a follow-up question\n",
    "    user_qa_query = \"What rules apply to my landlord entering my rental?\"\n",
    "    \n",
    "    # 2.2 Use RAG 2 to retrieve the General Q&A context\n",
    "    qa_context = general_qa_retriever.invoke(user_qa_query)\n",
    "    \n",
    "    # 2.3 LLM Call for Answer (Simulated)\n",
    "    print(f\"\\nUser Q&A Query: {user_qa_query}\")\n",
    "    print(\"\\n[SIMULATED LLM ANSWER GENERATION]\")\n",
    "    print(f\"Retrieved General Q&A Context for LLM:\")\n",
    "    for doc in qa_context:\n",
    "        print(f\"  - Length: {len(doc.page_content)}. Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        \n",
    "    # *A real LLM would now synthesize these into a single, cohesive answer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48039408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking down user uploaded TA\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document # Needed to wrap the user text\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os # To handle file paths\n",
    "\n",
    "def load_and_extract_pdf_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Checks if a file is a PDF, loads it, and extracts all text content.\n",
    "    \n",
    "    Args:\n",
    "        file_path: The local path to the user's uploaded file.\n",
    "\n",
    "    Returns:\n",
    "        A single string containing all text from the PDF.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the file is not found or is not a PDF.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Loading and Extracting Text from: {file_path} ---\")\n",
    "\n",
    "    # 1. Basic File Check\n",
    "    if not os.path.exists(file_path):\n",
    "        raise ValueError(f\"Error: File not found at path: {file_path}\")\n",
    "\n",
    "    # 2. PDF Extension Check (Simple approach)\n",
    "    if not file_path.lower().endswith('.pdf'):\n",
    "        raise ValueError(f\"Error: File is not a PDF ('.pdf' extension required).\")\n",
    "\n",
    "    try:\n",
    "        # 3. Use LangChain's PyPDFLoader for robust text extraction\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        \n",
    "        # Load all pages as a list of Document objects\n",
    "        pages = loader.load()\n",
    "        print(f\"Successfully loaded {len(pages)} pages.\")\n",
    "\n",
    "        # 4. Concatenate all page content into a single string\n",
    "        full_text = \"\\n\\n\".join(page.page_content for page in pages)\n",
    "        \n",
    "        # Simple cleanup (optional, but helps with messy PDF parsing)\n",
    "        full_text = re.sub(r'\\s{2,}', ' ', full_text) # Replace multiple spaces/newlines with single space\n",
    "        full_text = re.sub(r'(\\n\\s*){2,}', '\\n\\n', full_text) # Preserve paragraph breaks\n",
    "\n",
    "        print(\"Text extraction complete.\")\n",
    "        return full_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Catch errors during PDF parsing\n",
    "        raise RuntimeError(f\"An error occurred during PDF text extraction: {e}\")\n",
    "\n",
    "def split_user_document(user_uploaded_text: str, source_name: str = \"User TA\") -> list[Document]:\n",
    "    \"\"\"\n",
    "    Splits the raw text of the user-uploaded tenancy agreement into clause-level chunks.\n",
    "\n",
    "    Args:\n",
    "        user_uploaded_text: The raw string content of the user's document.\n",
    "        source_name: A metadata tag to identify the source (e.g., the filename).\n",
    "\n",
    "    Returns:\n",
    "        A list of LangChain Document objects, one for each clause/chunk.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- SPLITTING USER DOCUMENT: {source_name} ---\")\n",
    "\n",
    "    # The same structure-aware separators used for your Ideal Clauses (RAG 1)\n",
    "    custom_separators = [\n",
    "        \"\\n\\n\",\n",
    "        r\"\\n\\s*[A-Z]+\\s+\\d*\\s*\\.\",\n",
    "        r\"\\n\\s*\\d+\\.\\d*\\s*\",\n",
    "        r\"\\n\\s*\\([a-zA-Z0-9]+\\)\\s*\",\n",
    "        \"\\n\", \" \", \"\"\n",
    "    ]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200,\n",
    "        separators=custom_separators,\n",
    "        is_separator_regex=True\n",
    "    )\n",
    "\n",
    "    # 1. Convert the single raw string into a list of Documents (one initial document)\n",
    "    initial_document = [\n",
    "        Document(page_content=user_uploaded_text, metadata={\"source\": source_name})\n",
    "    ]\n",
    "\n",
    "    # 2. Split the document based on the clause structure\n",
    "    user_chunks = text_splitter.split_documents(initial_document)\n",
    "    \n",
    "    print(f\"User TA split into {len(user_chunks)} clause-level chunks.\")\n",
    "    \n",
    "    # Optional: Print a preview of the first few chunks\n",
    "    for i, chunk in enumerate(user_chunks[:3]):\n",
    "        print(f\"  Chunk {i+1} (Length: {len(chunk.page_content)}): {chunk.page_content[:150].replace('\\n', ' ')}...\")\n",
    "    \n",
    "    return user_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84269562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client initialized successfully from environment variable.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from langchain_core.documents import Document \n",
    "# Import the OpenAI library\n",
    "from openai import OpenAI\n",
    "import os \n",
    "import textwrap\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- LLM CONFIGURATION for OpenAI ---\n",
    "# Recommended model for this task (fast and good at structured output)\n",
    "LLM_MODEL = \"gpt-4o-mini\" \n",
    "MAX_RETRIES = 3\n",
    "load_dotenv()  # Load environment variables from a .env file if present\n",
    "# Get the API key from the environment variable\n",
    "api_key_from_env = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key_from_env:\n",
    "    try:\n",
    "        # Pass the key explicitly to ensure the client is initialized correctly\n",
    "        client = OpenAI(api_key=api_key_from_env)\n",
    "        print(\"OpenAI client initialized successfully from environment variable.\")\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL ERROR: Failed to initialize OpenAI client even with key. Error: {e}\")\n",
    "        client = None\n",
    "else:\n",
    "    # If the key is not found, print a clear warning and set client to None\n",
    "    print(\"OPENAI_API_KEY environment variable is NOT set.\")\n",
    "    client = None\n",
    "\n",
    "def llm_compare_and_critique_openai(\n",
    "    user_clause_text: str, \n",
    "    ideal_context_docs: List[Document]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Compares a user's tenancy clause against retrieved ideal context using the OpenAI API.\n",
    "    \n",
    "    The function uses structured JSON output enforcement for reliability.\n",
    "\n",
    "    Args:\n",
    "        user_clause_text: The content of the user's clause chunk.\n",
    "        ideal_context_docs: A list of relevant ideal clauses retrieved from the RAG 1 Vector Store.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the feedback, risk level, and suggestions.\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return {\n",
    "            \"clause_summary\": \"API Initialization Failed\",\n",
    "            \"risk_level\": \"HIGH\",\n",
    "            \"feedback\": \"OpenAI client is not configured correctly. Check API key.\",\n",
    "            \"suggestion\": \"Set the OPENAI_API_KEY environment variable.\"\n",
    "        }\n",
    "\n",
    "    print(f\"\\n[CRITIQUE] Analyzing clause with GPT: {user_clause_text[:50]}...\")\n",
    "\n",
    "    # 1. FORMAT THE CONTEXT FOR THE LLM\n",
    "    context_str = \"\\n---\\n\".join([doc.page_content for doc in ideal_context_docs])\n",
    "    \n",
    "    # 2. DEFINE SYSTEM INSTRUCTION\n",
    "    # This sets the persona and output constraints.\n",
    "    system_instruction = (\n",
    "        \"You are a world-class legal analyst specializing in residential tenancy agreements. \"\n",
    "        \"Your task is to compare a provided 'User Clause' against 'Ideal Clause Examples' \"\n",
    "        \"and generate structured, actionable feedback. Be concise, professional, and focus only on deviations or missing protections for the tenant. \"\n",
    "        \"Your entire output MUST be a single, valid JSON object that strictly adheres to the provided JSON Schema.\"\n",
    "    )\n",
    "\n",
    "    # 3. DEFINE THE USER QUERY (THE CORE PROMPT)\n",
    "    user_query = textwrap.dedent(f\"\"\"\n",
    "        Please analyze the following 'User Clause' and compare it to the 'Ideal Clause Examples'.\n",
    "\n",
    "        **USER CLAUSE TO CRITIQUE:**\n",
    "        ---\n",
    "        {user_clause_text}\n",
    "        ---\n",
    "\n",
    "        **IDEAL CLAUSE EXAMPLES (RAG Context):**\n",
    "        ---\n",
    "        {context_str}\n",
    "        ---\n",
    "\n",
    "        Based on your comparison, provide the analysis in the specified JSON format.\n",
    "    \"\"\")\n",
    "\n",
    "    # 4. DEFINE THE JSON SCHEMA\n",
    "    response_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"clause_summary\": {\"type\": \"string\", \"description\": \"A brief (1-sentence) summary of the user clause's main topic.\"},\n",
    "            \"risk_level\": {\"type\": \"string\", \"enum\": [\"LOW\", \"MEDIUM\", \"HIGH\"], \"description\": \"The risk level (LOW, MEDIUM, or HIGH) for the tenant based on deviations from the ideal.\"},\n",
    "            \"feedback\": {\"type\": \"string\", \"description\": \"Specific, actionable criticism on what is missing or concerning in the User Clause.\"},\n",
    "            \"suggestion\": {\"type\": \"string\", \"description\": \"A brief sentence on how the user should attempt to modify the clause.\"}\n",
    "        },\n",
    "        \"required\": [\"clause_summary\", \"risk_level\", \"feedback\", \"suggestion\"]\n",
    "    }\n",
    "\n",
    "\n",
    "    # 5. EXECUTE API CALL WITH EXPONENTIAL BACKOFF\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=LLM_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_instruction},\n",
    "                    {\"role\": \"user\", \"content\": user_query}\n",
    "                ],\n",
    "                # Use the response_format tool for guaranteed JSON output (GPT-4o/GPT-4 models)\n",
    "                response_format={\"type\": \"json_object\"}, \n",
    "                # Note: The JSON structure is also implicitly constrained by the prompt and system instruction.\n",
    "                temperature=0.0 # Use low temperature for analytical tasks\n",
    "            )\n",
    "            \n",
    "            # Extract and parse the JSON response text\n",
    "            # The entire output text should be a single JSON string\n",
    "            json_text = response.choices[0].message.content\n",
    "            parsed_json = json.loads(json_text)\n",
    "            print(f\"... Successful critique generated on attempt {attempt + 1}.\")\n",
    "            return parsed_json\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                print(f\"OpenAI API Error: {e}. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"OpenAI API failed after {MAX_RETRIES} attempts.\")\n",
    "                return {\n",
    "                    \"clause_summary\": \"Analysis Failed\",\n",
    "                    \"risk_level\": \"HIGH\",\n",
    "                    \"feedback\": f\"Unable to generate critique after {MAX_RETRIES} attempts. Error: {e}\",\n",
    "                    \"suggestion\": \"Check your API key, model permissions, and rate limits.\"\n",
    "                }\n",
    "    \n",
    "    # Should be unreachable\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Integrating LLM for RAG\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_NAME = 'Database Requirements.xlsx'\n",
    "DATA_DIRECTORY = \"./TA_template\" \n",
    "\n",
    "# Initialize shared embedding model once\n",
    "embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. BUILD THE TWO RAG SYSTEMS\n",
    "    ideal_clauses_retriever = build_ideal_clauses_retriever(DATA_DIRECTORY)\n",
    "    general_qa_retriever = build_general_qa_retriever(FILE_NAME)\n",
    "\n",
    "    print(\"\\n✅ BOTH RAG SYSTEMS ARE READY.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    # --- PHASE 1: CLAUSE IDENTIFICATION & COMPARISON (RAG 1) ---\n",
    "    # --- Placeholder: Replace this with the actual path to the user's uploaded file ---\n",
    "    USER_UPLOADED_FILE_PATH = \"./TA_sample/TA3.pdf\" \n",
    "    # Note: In a real-world application, this path comes from your web/API framework after the user submits the file.\n",
    "\n",
    "    try:\n",
    "        # 1. LOAD & EXTRACT TEXT from the PDF\n",
    "        full_user_document_text = load_and_extract_pdf_text(USER_UPLOADED_FILE_PATH)\n",
    "\n",
    "        # 2. SPLIT the extracted text into clauses\n",
    "        user_clause_chunks = split_user_document(\n",
    "            full_user_document_text, \n",
    "            source_name=USER_UPLOADED_FILE_PATH\n",
    "        )\n",
    "\n",
    "        # 3. Loop through ALL user clauses for comparison (The RAG Core)\n",
    "        feedback_report = []\n",
    "\n",
    "        for user_clause in user_clause_chunks:\n",
    "            # Use RAG 1 to retrieve the Ideal Clause context\n",
    "            comparison_context = ideal_clauses_retriever.invoke(user_clause.page_content)\n",
    "            \n",
    "            # 4. LLM Call for Feedback (Simulated)\n",
    "            feedback = llm_compare_and_critique_openai(user_clause.page_content, comparison_context)\n",
    "            feedback_report.append(feedback)\n",
    "\n",
    "        print(\"\\n--- Phase 1 Complete: Analysis ready. ---\")\n",
    "        \n",
    "    except (ValueError, RuntimeError) as e:\n",
    "        # Handle the specific errors raised by the extraction function\n",
    "        print(f\"\\nFATAL ERROR DURING FILE PROCESSING: {e}\")\n",
    "        # You would typically stop processing here and inform the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
